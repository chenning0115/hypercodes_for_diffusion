{
    "epoch_loss": {
        "type": "index_value",
        "index": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15,
            16,
            17,
            18,
            19,
            20
        ],
        "value": [
            1.223906015100827,
            0.3193058643361137,
            0.08728373329128139,
            0.03124201346199238,
            0.01637408433271218,
            0.010712275141719433,
            0.007816043082133312,
            0.006074324328630075,
            0.0049000606411271725,
            0.00405872771773449,
            0.003427500158097069,
            0.0029379709423811525,
            0.0025491579762469173,
            0.00223506124227563,
            0.001977421105922077,
            0.0017635785937317977,
            0.0015818480713906287,
            0.0014264271080570593,
            0.0012943147407440422,
            0.0011795313680484382
        ]
    },
    "train_oa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            99.02062109355776,
            99.02308184457897
        ]
    },
    "train_aa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            98.44877129292196,
            98.46708295873418
        ]
    },
    "train_kappa": {
        "type": "index_value",
        "index": [
            10,
            20
        ],
        "value": [
            98.70212542156186,
            98.70539740506105
        ]
    },
    "param": {
        "data": {
            "data_sign": "Pavia",
            "diffusion_sign": true,
            "diffusion_data_sign_path_prefix": "../../data/pavia_unet3d_patch16_without_downsample_kernal5_fix/save_feature",
            "diffusion_data_sign": "t10_2_full.pkl.npy",
            "patch_size": 9,
            "test_ratio": 0.95,
            "batch_size": 64,
            "num_classes": 9,
            "pca": 1200,
            "spectral_size": 1200
        },
        "net": {
            "trainer": "cross_trainer",
            "net_type": "just_pixel",
            "mlp_head_dim": 64,
            "depth": 5,
            "dim": 64,
            "conv3d_kernal_size": [
                3,
                3,
                3
            ],
            "conv3d_padding": [
                2,
                1,
                1
            ]
        },
        "train": {
            "epochs": 20,
            "lr": 0.001,
            "weight_decay": 0
        }
    },
    "eval": {
        "classification": "              precision    recall  f1-score   support\n\n           0     0.9863    0.9748    0.9805      6299\n           1     0.9988    0.9997    0.9993     17717\n           2     0.9919    0.9799    0.9859      1994\n           3     0.9675    0.9808    0.9741      2911\n           4     0.9984    1.0000    0.9992      1278\n           5     0.9987    0.9996    0.9992      4778\n           6     0.9944    0.9905    0.9925      1263\n           7     0.9546    0.9746    0.9645      3498\n           8     0.9977    0.9622    0.9796       900\n\n    accuracy                         0.9902     40638\n   macro avg     0.9876    0.9847    0.9861     40638\nweighted avg     0.9903    0.9902    0.9902     40638\n",
        "oa": 99.02308184457897,
        "confusion": "[[ 6140     1     1    33     0     2     4   118     0]\n [    0 17712     0     5     0     0     0     0     0]\n [    3     0  1954    10     0     0     0    25     2]\n [   18    14     0  2855     0     4     1    19     0]\n [    0     0     0     0  1278     0     0     0     0]\n [    0     2     0     0     0  4776     0     0     0]\n [   12     0     0     0     0     0  1251     0     0]\n [   50     4    14    21     0     0     0  3409     0]\n [    2     0     1    27     2     0     2     0   866]]",
        "each_acc": "[ 97.47578981  99.97177852  97.99398195  98.07626245 100.\n  99.95814148  99.04988124  97.45568897  96.22222222]",
        "aa": 98.46708295873418,
        "kappa": 98.70539740506105
    }
}